import pandas as pd
import numpy as np
import os as _os, sys as _sys
from typing import Dict, Tuple
import warnings
import hashlib
try:
    import statsmodels.api as sm
    from statsmodels.tools.sm_exceptions import IterationLimitWarning
except Exception:
    raise RuntimeError("éœ€è¦å®‰è£… statsmodels>=0.13 æ‰èƒ½è¿è¡Œ QuantRegï¼ˆpip install statsmodelsï¼‰ã€‚")

# ç¡®ä¿å¯ä»¥ä»¥ç»å¯¹æ–¹å¼å¯¼å…¥ `glm_plus`ï¼ˆæŠŠé¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼‰
_PROJECT_ROOT = _os.path.abspath(_os.path.join(_os.path.dirname(__file__), '..'))
if _PROJECT_ROOT not in _sys.path:
    _sys.path.insert(0, _PROJECT_ROOT)
from glm_plus.frequentist.torque import FrequentistOQR
from matplotlib import pyplot as plt

# ==================== å¸¸é‡ä¸é…ç½® ====================
# åˆ†ä½ç‚¹é›†åˆï¼šç»†åŒ–åˆ° 0.1..0.9ï¼ˆå« 9 ä¸ªç‚¹ï¼‰ï¼Œä¾¿äº granularity åˆ†æ
# QUANTILES_MAIN = (0.2, 0.5, 0.8)
QUANTILES_MAIN = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
ORDER_LABELS = ["Assistant/Junior", "Regular", "Leader", "Chief/Founder"]

# Granularity å¸¦åŒºä¸å¯¹æ¯”å¯¹è®¾ç½®
BANDS_DEF = {
    'low': (0.1, 0.2),
    'low_mid': (0.3, 0.4),
    'mid': (0.5,),
    'mid_high': (0.6, 0.7),
    'high': (0.8, 0.9),
}
COMPARE_PAIRS = (
    ('mid', 'low'),
    ('mid', 'high'),
    ('low', 'high'),
)

# ä¼°è®¡å¯¹è±¡ï¼ˆestimandï¼‰ä¸äºŒé˜¶æ®µå¼€å…³
# - 'single_index': å…³é—­ two-indexï¼Œåªåœ¨ h(Y) å°ºå­ä¸ŠæŠ½ç³»æ•°ï¼ˆè§£é‡Šæœ€ç›´è§‚ï¼‰
# - 'final_combo': ä¿æŒ two-indexï¼Œä¸€å¾‹æŠ½â€œæœ€ç»ˆç»„åˆâ€u_tau = XÎ²1 + g^{-1}(XÎ²2,Ï„) çš„çº¿æ€§è¿‘ä¼¼ç³»æ•°
ESTIMAND_MODE = 'single_index'  # å¯æ”¹ä¸º 'final_combo'
# Bootstrap æ¬¡æ•°ï¼ˆ200 å·²è¶³å¤Ÿç¨³å¥ï¼›å¦‚éœ€æ›´ç¨³å¯æ”¹ 500ï¼‰
N_BOOTSTRAP_DEFAULT = 200
# QuantReg å®¹å·®ï¼ˆæé«˜æ”¶æ•›ç¨³å®šæ€§ï¼‰
QR_P_TOL = 1e-6

# â€”â€” æ•ˆåº”é‡é˜ˆå€¼ï¼ˆé¿å…â€œæ˜¾è‘—ä½†æ— æ„ä¹‰â€ï¼‰â€”â€”
# åªæœ‰å½“ |Î”| â‰¥ Îµ ä¸” CI ä¸è·¨ 0 æ‰å°† Î” åˆ¤ä¸º sticky/glass
# Îµ å¯æŒ‰ h(Y) çš„ SD æˆ– IQR çš„æ¯”ä¾‹è®¾å®š
EFFECT_SIZE_MODE = 'sd_pct'   # å¯é€‰: 'sd_pct' æˆ– 'iqr_pct'
EPSILON_SD_FRAC = 0.02        # Îµ = 2% * sd(h(Y))
EPSILON_IQR_FRAC = 0.01       # Îµ = 1% * IQR(h(Y))

# â€”â€” å¯é€‰ï¼šç½®æ¢æ£€éªŒï¼ˆé»˜è®¤å…³é—­ï¼Œè®¾ä¸º >0 å¼€å¯ï¼Œä¾‹å¦‚ 500ï¼‰â€”â€”
N_PERMUTATION_DEFAULT = 0

# â€”â€” æ¦‚ç‡å·®é˜ˆå€¼ï¼ˆå¯è§£é‡Šé‡çº²ï¼‰ï¼šè‡³å°‘ 2 ä¸ªç™¾åˆ†ç‚¹ â€”â€”
PROB_DIFF_THRESHOLD = 0.02

# æ˜¯å¦åœ¨ä¿å­˜åæ˜¾ç¤ºå›¾çª—ï¼ˆåœ¨ç»ˆç«¯è¿è¡Œæ—¶ä¼šé˜»å¡ï¼‰ï¼Œé»˜è®¤ä¸æ˜¾ç¤º
SHOW_FIG = False

# ç®€å•è¿›åº¦æ—¥å¿—å‡½æ•°ï¼ˆæŒ‰æ­¥éª¤æ‰“å°ï¼Œä¾¿äºåˆå­¦è€…ç†è§£ï¼‰
def _log(msg: str) -> None:
    print(f"[Progress] {msg}")

# subsample è§„åˆ™ï¼šå¤§æ ·æœ¬ä¸‹åŠ é€Ÿæ‹Ÿåˆï¼›ä¸æ”¹å˜ä¼°è®¡å«ä¹‰
SUBSAMPLE_RULE = lambda n: (5000 if n > 20000 else (3000 if n > 3000 else None))

# è¾“å‡ºç›®å½•
import os
OUTPUT_DIR = "output_results"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ç»Ÿä¸€æ‹Ÿåˆå‡½æ•°ï¼ˆä¿æŒä¸ä½ ç°æœ‰ pipeline ä¸€è‡´çš„é…ç½®ï¼‰
def fit_model(X: np.ndarray, y: np.ndarray, taus=QUANTILES_MAIN, random_state: int = 0) -> FrequentistOQR:
    # æœ€å°æ”¹æ³•ï¼šæ¯å›½åªæ‹Ÿåˆä¸€æ¬¡ï¼›å›ºå®šå•æŒ‡æ•°ï¼›è½»é‡ç½‘æ ¼ä»¥æé€Ÿ
    subsample_dynamic = SUBSAMPLE_RULE(X.shape[0]) or 2000
    m = FrequentistOQR(
        quantiles=taus,
        use_two_index=False,
        auto_select_k=True,
        subsample_n=int(subsample_dynamic),
        rank_grid_n=25,
        t_grid_n=31,
        random_state=random_state,
        qr_p_tol=QR_P_TOL,
    )
    m.fit(X, y)
    return m

# ==================== Step 1: è¯»å–æ•°æ® ====================
_log("[1/3] è¯»å–æ•°æ®å¹¶æ¸…æ´—ç±»åˆ«/å“‘å…ƒ...")
_DATA_DIR = "/Users/lei/Documents/Sequenzo_all_folders/sequenzo_local/test_data/real_data_my_paper/"
_CSV_PATH = _os.path.join(_DATA_DIR, "df_seniority.csv")
assert _os.path.exists(_CSV_PATH), f"æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {_CSV_PATH}"
df_seniority = pd.read_csv(_CSV_PATH)
assert 'country' in df_seniority.columns, "df_seniority éœ€è¦åŒ…å« 'country' åˆ—"

# â€”â€” ç»Ÿä¸€æ¸…æ´— Y10 æ ‡ç­¾ï¼Œé¿å…å¤§å°å†™/ç©ºæ ¼å¯¼è‡´çš„ä¸¢è¡Œ â€”â€”
_CANON_MAP = {
    "assistant/junior": "Assistant/Junior",
    "regular": "Regular",
    "leader": "Leader",
    "chief/founder": "Chief/Founder",
}

def _canonize_y10(val: str) -> str:
    s = str(val).strip().lower()
    if not s:
        return s
    # å½’ä¸€åŒ–åˆ†éš”ç¬¦ä¸ç©ºæ ¼
    for ch in ["&", "and", "-", "_"]:
        s = s.replace(ch, "/")
    s = "/".join([t.strip() for t in s.split("/") if t.strip()])
    # å…³é”®è¯æ˜ å°„
    if "assistant" in s or "junior" in s:
        key = "assistant/junior"
    elif "regular" in s:
        key = "regular"
    elif "leader" in s:
        key = "leader"
    elif "chief" in s or "founder" in s:
        key = "chief/founder"
    else:
        # æœªè¯†åˆ«åˆ™åŸæ ·è¿”å›ï¼ˆåç»­å°†è¢«ä¸¢å¼ƒï¼Œä¸”æ‰“å°æç¤ºï¼‰
        return str(val).strip()
    return _CANON_MAP[key]

df_seniority['Y10'] = df_seniority['Y10'].apply(_canonize_y10)
unknown_labels = sorted(set(df_seniority['Y10']) - set(ORDER_LABELS))
if unknown_labels:
    print(f"[warn] Y10 ä¸­å­˜åœ¨æœªè¯†åˆ«æ ‡ç­¾ï¼Œå°†è¢«ä¸¢å¼ƒ: {unknown_labels}")
    vc = df_seniority['Y10'].value_counts()
    unk_counts = {lab: int(vc.get(lab, 0)) for lab in unknown_labels}
    print(f"[warn] æœªè¯†åˆ«æ ‡ç­¾çš„æ ·æœ¬é‡: {unk_counts}")
print("[info] å·²çŸ¥æ ‡ç­¾æ ·æœ¬é‡:")
print(df_seniority['Y10'].value_counts().reindex(ORDER_LABELS).fillna(0).astype(int))

# â€”â€” é¢„å»ºç«‹å…¨å±€å“‘å…ƒåˆ—é›†åˆï¼Œç¡®ä¿å„å›½è®¾è®¡çŸ©é˜µåˆ—ä¸€è‡´ â€”â€”
_CAT_COLS = ['highest_educational_degree', 'internationalization', 'company_size']
global_cat_dummies = pd.get_dummies(df_seniority[_CAT_COLS], columns=_CAT_COLS, drop_first=True, dtype=int)
GLOBAL_DUMMY_COLUMNS = list(global_cat_dummies.columns)

_log("[1/3] æ•°æ®åŠ è½½ä¸æ¸…æ´—å®Œæˆ")

# è®¾è®¡çŸ©é˜µæ„é€ ï¼ˆå°ç™½å‹å¥½ï¼šæŠŠ y ç¼–ç ã€female æŒ‡ç¤ºå˜é‡ã€ç±»åˆ«å“‘å…ƒéƒ½åœ¨è¿™é‡Œåšï¼‰
def build_design_for_subset(df_sub: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, np.ndarray, np.ndarray]:
    cols_needed = [
        'gender', 'highest_educational_degree',
        'whether_bachelor_university_prestigious',
        'internationalization', 'work_years', 'company_size', 'Y10'
    ]
    d = df_sub[cols_needed].dropna().copy()
    # y: æŠŠèŒä½ç­‰çº§è½¬ä¸ºæœ‰åºç±»åˆ«ï¼Œå†ç¼–ç ä¸º 1..J
    cat_type = pd.CategoricalDtype(categories=ORDER_LABELS, ordered=True)
    d['y_cat'] = d['Y10'].astype(cat_type)
    d = d[~d['y_cat'].isna()].copy()
    d['y'] = d['y_cat'].cat.codes + 1
    # female: æ–‡æœ¬è½¬å°å†™ååŒ¹é…
    gg = d['gender'].astype(str).str.strip().str.lower()
    d['female'] = (gg == 'female').astype(int)
    # prestigious_bachelor: ç»Ÿä¸€æˆ 0/1
    col_p = 'whether_bachelor_university_prestigious'
    if str(d[col_p].dtype) == 'bool':
        d['prestigious_bachelor'] = d[col_p].astype(int)
    else:
        d['prestigious_bachelor'] = (
            d[col_p].astype(str).str.strip().str.lower().isin(['true','1','yes','y','t'])
        ).astype(int)
    # work_years: è½¬æ•°å€¼
    d['work_years'] = pd.to_numeric(d['work_years'], errors='coerce')
    d = d.dropna(subset=['work_years']).copy()
    # one-hot: ç±»åˆ«å˜é‡åšå“‘å…ƒï¼ˆdrop_first=True ä»¥é¿å…å®Œå…¨å…±çº¿ï¼‰
    cat_cols = _CAT_COLS
    X_cat = pd.get_dummies(d[cat_cols], columns=cat_cols, drop_first=True, dtype=int)
    # ç»Ÿä¸€åˆ°å…¨å±€å“‘å…ƒåˆ—
    X_cat = X_cat.reindex(columns=GLOBAL_DUMMY_COLUMNS, fill_value=0)
    X_df = pd.concat([
        d[['female', 'prestigious_bachelor', 'work_years']].reset_index(drop=True),
        X_cat.reset_index(drop=True)
    ], axis=1)
    X = X_df.to_numpy(dtype=float)
    y = d['y'].to_numpy(dtype=int)
    if d['female'].nunique() < 2:
        try:
            _ctry = str(df_sub.get('country', '').iloc[0]) if 'country' in df_sub.columns else ''
        except Exception:
            _ctry = ''
        print(f"[warn] è¯¥å­é›† female åªæœ‰ä¸€ä¸ªå–å€¼ï¼Œåˆ†ä½ç³»æ•°å¯èƒ½ä¸å¯è¯†åˆ«æˆ–ä¸ç¨³ã€‚country={_ctry}")
    return d, X_df, X, y

# ==================== Step 2: å·¥å…·å‡½æ•°ï¼ˆæŠ½ç³»æ•° + CI + pï¼‰ ====================
def _extract_female_coef_by_tau(model: FrequentistOQR, X_df: pd.DataFrame, X: np.ndarray, taus, mode: str = ESTIMAND_MODE, warn_counter: Dict[str, int] | None = None) -> Dict[float, float]:
    """
    è¿”å› {tau: female ç³»æ•°}ï¼ˆåœ¨æ¨¡å‹å½“å‰æ‹Ÿåˆä¸‹ï¼‰ã€‚
    ä¼˜å…ˆä½¿ç”¨æ¨¡å‹å†…å­˜å‚¨ï¼›å¦åˆ™ç”¨ h(Y) çš„è¿ç»­å“åº”é‡æ–°åš QuantReg å…œåº•ã€‚
    """
    coef_by_tau: Dict[float, float] = {}
    female_idx = int(X_df.columns.get_loc('female'))

    # å…¨å±€å·²å¯¼å…¥ sm ä¸ IterationLimitWarning

    # Single-indexï¼šç›´æ¥åœ¨ h(Y) ä¸ŠæŠ½ç³»æ•°
    if mode == 'single_index':
        # 1) ä¼˜å…ˆå°è¯•ï¼šæ¨¡å‹å†…éƒ¨æ˜¯å¦å·²æš´éœ² per-Ï„ çš„ QR ç»“æœ
        qr_store = getattr(model, 'qr_models_', None) or getattr(model, 'qr_results_', None)
        if isinstance(qr_store, dict) and len(qr_store) > 0:
            for tau in taus:
                res = qr_store.get(tau, None)
                if res is not None and hasattr(res, 'params'):
                    coef_by_tau[float(tau)] = float(np.asarray(res.params, dtype=float)[female_idx])
        # 2) å…œåº•ï¼šä½¿ç”¨ h_iso_ å’Œ _y_jit é‡å»ºè¿ç»­å“åº”ï¼Œå†å¯¹ (hy, X) åš QuantReg
        missing = [t for t in taus if float(t) not in coef_by_tau]
        if missing:
            hy = None
            try:
                hy = model.h_iso_.transform(getattr(model, '_y_jit'))  # type: ignore[attr-defined]
            except Exception:
                hy = None
            if hy is None:
                for name in ('y_tilde_', 'y_cont_', 'y_transformed_', 'y_star_', 'y_continuous_'):
                    hy = getattr(model, name, None)
                    if hy is not None:
                        break
            if hy is None:
                raise RuntimeError("æ— æ³•è·å–æ¨¡å‹çš„è¿ç»­å“åº”ï¼ˆh(Y)ï¼‰ã€‚å¯ç”¨ dir(model) æŸ¥çœ‹å®é™…å­—æ®µåååŠ å…¥å€™é€‰åˆ—è¡¨ã€‚")
            hy = np.asarray(hy, dtype=float).reshape(-1)
            X_used = np.asarray(X, dtype=float)
            if X_used.shape[0] != hy.shape[0]:
                X_last = getattr(model, '_last_X_', None)
                if X_last is None or np.asarray(X_last).shape[0] != hy.shape[0]:
                    raise RuntimeError("X ä¸è¿ç»­å“åº”é•¿åº¦ä¸åŒ¹é…ï¼Œä¸” model._last_X_ ä¸å¯ç”¨ã€‚")
                X_used = np.asarray(X_last, dtype=float)
            for tau in missing:
                with warnings.catch_warnings(record=True) as w:
                    warnings.simplefilter("always", IterationLimitWarning)
                    try:
                        res = sm.QuantReg(hy, X_used).fit(q=float(tau), max_iter=5000, p_tol=QR_P_TOL)
                    except TypeError:
                        res = sm.QuantReg(hy, X_used).fit(q=float(tau), max_iter=5000)
                if warn_counter is not None:
                    warn_counter['fit_count'] = warn_counter.get('fit_count', 0) + 1
                    warn_counter['warn_count'] = warn_counter.get('warn_count', 0) + sum(1 for wi in w if issubclass(wi.category, IterationLimitWarning))
                coef_by_tau[float(tau)] = float(np.asarray(res.params, dtype=float)[female_idx])
        return coef_by_tau

    # final_comboï¼šå¯¹ u_tau = XÎ²1 + g^{-1}(XÎ²2,Ï„) åšä¸€é Ï„-QuantRegï¼ŒæŠ½ female ç³»æ•°
    X_used = np.asarray(X, dtype=float)
    X_last = getattr(model, '_last_X_', None)
    if X_last is not None and X_used.shape[0] != np.asarray(X_last).shape[0]:
        X_used = np.asarray(X_last, dtype=float)
    xb1 = X_used @ (model.beta1_.reshape(-1) if model.beta1_ is not None else np.zeros(X_used.shape[1]))
    for tau in taus:
        u_tau = xb1.copy()
        if getattr(model, 'use_two_index', False) and getattr(model, 'beta2_tau_', None) is not None:
            b2t = model.beta2_tau_.get(float(tau), model.beta2_)
            if b2t is None and isinstance(model.beta2_tau_, dict) and len(model.beta2_tau_) > 0:
                b2t = next(iter(model.beta2_tau_.values()))
            if b2t is not None:
                u2 = (X_used @ b2t.reshape(-1))
                try:
                    r_tau = model._ginv(u2)
                except Exception:
                    r_tau = u2
                u_tau = u_tau + r_tau
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always", IterationLimitWarning)
            try:
                res = sm.QuantReg(u_tau, X_used).fit(q=float(tau), max_iter=5000, p_tol=QR_P_TOL)
            except TypeError:
                res = sm.QuantReg(u_tau, X_used).fit(q=float(tau), max_iter=5000)
        if warn_counter is not None:
            warn_counter['fit_count'] = warn_counter.get('fit_count', 0) + 1
            warn_counter['warn_count'] = warn_counter.get('warn_count', 0) + sum(1 for wi in w if issubclass(wi.category, IterationLimitWarning))
        coef_by_tau[float(tau)] = float(np.asarray(res.params, dtype=float)[female_idx])

    return coef_by_tau

def _ci_from_samples(samples, level=0.95):
    arr = np.asarray(samples, dtype=float)
    arr = arr[np.isfinite(arr)]
    if arr.size == 0:
        return np.nan, np.nan, False
    lo = float(np.nanpercentile(arr, (1.0 - level) / 2.0 * 100.0))
    hi = float(np.nanpercentile(arr, (1.0 + level) / 2.0 * 100.0))
    sig = not (lo <= 0.0 <= hi)
    return lo, hi, sig

def _p_from_sign_two_sided(samples):
    arr = np.asarray(samples, dtype=float)
    return float(2.0 * min(np.mean(arr >= 0.0), np.mean(arr <= 0.0)))

# ==================== Step 3: æŒ‰å›½å®¶æå–â€œfemale åˆ†ä½ç³»æ•° + CIâ€ ====================
def analyze_by_country_detailed(min_n: int = 500, n_bootstrap: int = N_BOOTSTRAP_DEFAULT, random_state: int = 0) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    female_coef_rows = []            # ç‚¹ä¼°ï¼ˆé€ Ï„ï¼‰
    female_coef_boot_rows = []       # Bootstrap CIï¼ˆé€ Ï„ï¼‰
    band_rows = []                   # å¸¦åŒºèšåˆï¼ˆlow/low_mid/mid/mid_high/highï¼‰
    band_compare_rows = []           # å¸¦åŒºå¯¹æ¯”ï¼ˆmid-vs-lowã€mid-vs-highã€low-vs-highï¼‰
    delta_rows = []                  # å›½å®¶çº§ Î” å…œåº•æ±‡æ€»ï¼ˆåº• vs é¡¶ï¼Œç”¨äºä¸æ—§å£å¾„å¯¹æ¯”ï¼‰

    print("=== æŒ‰å›½å®¶æŠ½å– being female çš„åˆ†ä½ç³»æ•°ï¼ˆå«95% bootstrap CIï¼‰===")
    print("[note] æœ¬åˆ†æçŸ©é˜µä¸å«å¸¸æ•°åˆ—ï¼ˆæ‹¦æˆªé¡¹ï¼‰ï¼Œfemale ç³»æ•°ä¸ºç›¸å¯¹æ— æˆªè·çº¿æ€§é¡¹çš„è¾¹é™…æ•ˆåº”ã€‚")
    if ESTIMAND_MODE == 'final_combo':
        print("[note] final_combo æ¨¡å¼ï¼šå¯¹æœ€ç»ˆç»„åˆ u_Ï„ è¿›è¡Œçº¿æ€§æŠ•å½±ï¼ˆQuantRegï¼‰ï¼Œç³»æ•°ä¸ºçº¿æ€§è¿‘ä¼¼ï¼Œä¸ä½œç»“æ„æ€§è§£é‡Šã€‚")
    for ctry, df_g in df_seniority.groupby('country'):
        d, Xdf, Xg, yg = build_design_for_subset(df_g)
        n = len(yg)
        if n < min_n:
            print(f"{ctry}: è·³è¿‡ (n={n} < {min_n})")
            continue
        print(f"{ctry}: æ‹Ÿåˆæ¨¡å‹å¹¶è®°å½•ç‚¹ä¼° (n={n})â€¦")
        # è‹¥ female åˆ—ä¸å­˜åœ¨æˆ–æ— å˜å¼‚ï¼Œç›´æ¥è·³è¿‡ï¼ˆé¿å…æ— æ„ä¹‰çš„ bootstrap ä¸ Î” åˆ¤å®šï¼‰
        if ('female' not in Xdf.columns) or (Xdf['female'].nunique() < 2):
            print(f"[warn] è·³è¿‡ï¼š{ctry} çš„ female åˆ—ä¸å­˜åœ¨æˆ–æ— å˜å¼‚")
            continue

        # 1) æ‹Ÿåˆä¸»æ¨¡å‹å¹¶è®°å½•ç‚¹ä¼°æ›²çº¿
        m = fit_model(Xg, yg, taus=QUANTILES_MAIN, random_state=int(random_state))
        warn_counter = {'fit_count': 0, 'warn_count': 0}
        try:
            coef_point = _extract_female_coef_by_tau(m, Xdf, Xg, QUANTILES_MAIN, mode=ESTIMAND_MODE, warn_counter=warn_counter)
            for tau, val in coef_point.items():
                female_coef_rows.append({
                    'country': str(ctry), 'n': n, 'tau': float(tau),
                    'female_coef_point': float(val)
                })
        except Exception as e:
            print(f"[warn] æ— æ³•æŠ½å–ç³»æ•°ç‚¹ä¼°ï¼ˆ{ctry}ï¼‰ï¼š{e}")

        # 2) Bootstrapï¼šå›ºå®š h/gï¼Œä»…å¯¹ QR æŠ½æ ·ç³»æ•°ï¼ˆä¸€æ¬¡æ‹Ÿåˆ + æŠ½æ ·ï¼‰
        print(f"{ctry}: è¿›è¡Œ bootstrapï¼ˆ{int(n_bootstrap)} æ¬¡ï¼Œå›ºå®š h/gï¼Œä»… QR é‡ä¼°ï¼‰ä»¥æ„é€  CIâ€¦")
        seed = int(hashlib.md5(str(ctry).encode()).hexdigest()[:8], 16) + int(random_state)
        TAUS_FOR_BOOT = tuple(QUANTILES_MAIN)
        q_low, q_high = (min(QUANTILES_MAIN), max(QUANTILES_MAIN))
        female_idx = int(Xdf.columns.get_loc('female'))
        boot = m.bootstrap_inference(n_boot=int(n_bootstrap), random_state=seed, return_coefs=True)
        # å¸¸è§è¿”å›ï¼šbeta_tau[tau]['draws'] -> (n_boot, n_params)
        coef_boot = {float(tau): [] for tau in TAUS_FOR_BOOT}
        delta_boot = []
        for tau in TAUS_FOR_BOOT:
            draws = boot.get('beta_tau', {}).get(float(tau), {}).get('draws', None)
            if draws is None:
                continue
            coef_boot[float(tau)] = list(np.asarray(draws)[:, female_idx].reshape(-1))
        if (q_low in coef_boot) and (q_high in coef_boot) and len(coef_boot[q_low]) > 0 and len(coef_boot[q_high]) > 0:
            a = np.asarray(coef_boot[q_high], dtype=float)
            b = np.asarray(coef_boot[q_low], dtype=float)
            n_success = int(min(a.shape[0], b.shape[0]))
            delta_boot = list((a[:n_success] - b[:n_success]).reshape(-1))
        else:
            n_success = 0

        # 2.1) æ„é€ è¿ç»­å“åº” h(Y)ï¼Œç”¨äºæ•ˆåº”é‡é˜ˆå€¼è®¡ç®—ä¸å¯é€‰ç½®æ¢æ£€éªŒ
        hy = None
        try:
            hy = m.h_iso_.transform(getattr(m, '_y_jit'))  # type: ignore[attr-defined]
        except Exception:
            hy = None
        if hy is None:
            for name in ('y_tilde_', 'y_cont_', 'y_transformed_', 'y_star_', 'y_continuous_'):
                hy = getattr(m, name, None)
                if hy is not None:
                    break
        if hy is None:
            # è‹¥æ— æ³•ç›´æ¥è·å– h(Y)ï¼Œç”¨ X @ beta1_ è¿‘ä¼¼ï¼ˆä»…ç”¨äºå®šä¹‰å°ºåº¦ï¼Œä¸ä½œæ¨æ–­ï¼‰
            try:
                hy = (np.asarray(Xg, dtype=float) @ (m.beta1_.reshape(-1) if m.beta1_ is not None else np.zeros(Xg.shape[1])))
            except Exception:
                hy = np.asarray([np.nan] * Xg.shape[0])
        hy = np.asarray(hy, dtype=float).reshape(-1)
        hy_sd = float(np.nanstd(hy, ddof=1)) if np.isfinite(hy).all() else np.nan
        if np.isfinite(hy).all():
            hy_q25 = float(np.nanpercentile(hy, 25.0))
            hy_q75 = float(np.nanpercentile(hy, 75.0))
            hy_iqr = float(hy_q75 - hy_q25)
        else:
            hy_q25, hy_q75, hy_iqr = np.nan, np.nan, np.nan
        if EFFECT_SIZE_MODE == 'sd_pct' and np.isfinite(hy_sd):
            epsilon = float(EPSILON_SD_FRAC * hy_sd)
            epsilon_mode = 'sd_pct'
        elif EFFECT_SIZE_MODE == 'iqr_pct' and np.isfinite(hy_iqr):
            epsilon = float(EPSILON_IQR_FRAC * hy_iqr)
            epsilon_mode = 'iqr_pct'
        else:
            epsilon = np.nan
            epsilon_mode = 'undefined'

        # 3) CI ä¸æ˜¾è‘—æ€§
        bottom_sig_neg = False
        top_sig_neg = False
        bottom_sig_pos = False
        top_sig_pos = False
        for tau in QUANTILES_MAIN:
            samples = coef_boot.get(tau, [])
            if samples:
                lo, hi, sig = _ci_from_samples(samples, level=0.95)
                p_boot = _p_from_sign_two_sided(samples)
                # æ‰¾å¯¹åº”ç‚¹ä¼°
                pt = np.nan
                try:
                    pt = float([r['female_coef_point'] for r in female_coef_rows if (r['country'] == str(ctry) and abs(r['tau'] - float(tau)) < 1e-9)][-1])
                except Exception:
                    pass
                female_coef_boot_rows.append({
                    'country': str(ctry), 'n': n, 'tau': float(tau),
                    'female_coef_point': pt,
                    'female_coef_ci_low': lo, 'female_coef_ci_high': hi,
                    'female_coef_sig': sig, 'female_coef_p_boot': float(p_boot),
                    'ci_level': 0.95
                })
                if abs(float(tau) - float(q_low)) < 1e-9:
                    bottom_sig_neg = (hi < 0.0)
                    bottom_sig_pos = (lo > 0.0)
                if abs(float(tau) - float(q_high)) < 1e-9:
                    top_sig_neg = (hi < 0.0)
                    top_sig_pos = (lo > 0.0)

        # è‹¥ female åˆ—ä¸å­˜åœ¨æˆ–å…¨å¸¸æ•°ï¼Œè·³è¿‡åç»­ Î” åˆ¤å®š
        if 'female' not in Xdf.columns or Xdf['female'].nunique() < 2:
            print(f"[warn] è·³è¿‡ Î” åˆ¤å®šï¼š{ctry} çš„ female åˆ—ä¸å­˜åœ¨æˆ–æ— å˜å¼‚")
            continue

        # 3.1) ç›´æ¥æ£€éªŒ Î”_top-bottom çš„æ˜¾è‘—æ€§ï¼ˆå åŠ æ•ˆåº”é‡é˜ˆå€¼ Îµï¼‰
        delta_row = None
        if delta_boot:
            d_lo, d_hi, d_sig = _ci_from_samples(delta_boot, level=0.95)
            d_p = _p_from_sign_two_sided(delta_boot)
            d_point = np.nan
            try:
                pt_top = float([r['female_coef_point'] for r in female_coef_rows if (r['country'] == str(ctry) and abs(r['tau'] - float(q_high)) < 1e-9)][-1])
                pt_bot = float([r['female_coef_point'] for r in female_coef_rows if (r['country'] == str(ctry) and abs(r['tau'] - float(q_low)) < 1e-9)][-1])
                d_point = pt_top - pt_bot
            except Exception:
                pass
            delta_abs = float(abs(d_point)) if np.isfinite(d_point) else np.nan
            delta_std_sd = float(d_point / hy_sd) if (np.isfinite(d_point) and np.isfinite(hy_sd) and hy_sd > 0) else np.nan
            # æ¦‚ç‡å°ºåº¦ Î”_probï¼ˆåŸºäºä»£è¡¨æ€§æ ·æœ¬ã€Ï„ ç½‘æ ¼è¿‘ä¼¼ï¼‰ï¼š
            # Î”_prob = [P_bottom(f=1)-P_bottom(f=0)] - [P_top(f=1)-P_top(f=0)]
            delta_prob = np.nan
            prob_bottom_f0 = np.nan
            prob_bottom_f1 = np.nan
            prob_top_f0 = np.nan
            prob_top_f1 = np.nan
            try:
                # ä»£è¡¨æ€§æ ·æœ¬ï¼šä½¿ç”¨å„ç‰¹å¾çš„æ ·æœ¬å‡å€¼ï¼›ä»…åˆ‡æ¢ female=0/1
                x_rep = np.asarray(Xdf.mean(), dtype=float).reshape(-1)
                x0 = x_rep.copy(); x1 = x_rep.copy()
                x0[female_idx] = 0.0
                x1[female_idx] = 1.0
                # Ï„ ç½‘æ ¼
                tau_grid = np.linspace(0.02, 0.98, 41)
                y0_list = []
                y1_list = []
                rq_model = sm.QuantReg(hy, Xg)
                for t in tau_grid:
                    try:
                        rq = rq_model.fit(q=float(t), max_iter=5000, p_tol=QR_P_TOL)
                    except TypeError:
                        rq = rq_model.fit(q=float(t), max_iter=5000)
                    b = np.asarray(rq.params, dtype=float).reshape(-1)
                    hy0 = float(x0 @ b); hy1 = float(x1 @ b)
                    y0 = float(m._hinv(np.array([hy0]))[0])
                    y1 = float(m._hinv(np.array([hy1]))[0])
                    y0_list.append(y0)
                    y1_list.append(y1)
                y0_arr = np.asarray(y0_list, dtype=float)
                y1_arr = np.asarray(y1_list, dtype=float)
                # ç±»åˆ«è¾¹ç•Œ
                j_min = int(m._y_min_cat) if m._y_min_cat is not None else int(np.nanmin(yg))
                j_max = int(m._y_max_cat) if m._y_max_cat is not None else int(np.nanmax(yg))
                # åº•éƒ¨æ¦‚ç‡: P(Y<=j_min)
                mask0_bottom = (y0_arr <= float(j_min) + 1e-9)
                mask1_bottom = (y1_arr <= float(j_min) + 1e-9)
                prob_bottom_f0 = float(np.max(tau_grid[mask0_bottom])) if np.any(mask0_bottom) else 0.0
                prob_bottom_f1 = float(np.max(tau_grid[mask1_bottom])) if np.any(mask1_bottom) else 0.0
                # é¡¶éƒ¨æ¦‚ç‡: P(Y=j_max) = 1 - P(Y<=j_max-1)
                thresh_top = float(j_max - 1)
                mask0_topcdf = (y0_arr <= thresh_top + 1e-9)
                mask1_topcdf = (y1_arr <= thresh_top + 1e-9)
                F_topminus1_f0 = float(np.max(tau_grid[mask0_topcdf])) if np.any(mask0_topcdf) else 0.0
                F_topminus1_f1 = float(np.max(tau_grid[mask1_topcdf])) if np.any(mask1_topcdf) else 0.0
                prob_top_f0 = float(1.0 - F_topminus1_f0)
                prob_top_f1 = float(1.0 - F_topminus1_f1)
                delta_prob = (prob_bottom_f1 - prob_bottom_f0) - (prob_top_f1 - prob_top_f0)
            except Exception:
                delta_prob = np.nan

            # åˆ†ç±»è§„åˆ™ï¼ˆå«è¾¹è§’ï¼‰
            cls = 'no_heterogeneity'
            reason = 'è§„åˆ™æœªè§¦å‘æ˜¾è‘—å·®å¼‚'
            above_eps = (np.isfinite(delta_abs) and np.isfinite(epsilon) and delta_abs >= epsilon)
            meets_prob = (np.isfinite(delta_prob) and abs(float(delta_prob)) >= float(PROB_DIFF_THRESHOLD))
            if d_sig and above_eps and meets_prob and d_point > 0 and (delta_prob > 0):
                cls = 'sticky_floor'; reason = f'Î”>0ã€æ˜¾è‘—ï¼Œ|Î”|â‰¥Îµï¼ˆ{epsilon_mode}ï¼‰ï¼Œä¸” Î”_probâ‰¥{PROB_DIFF_THRESHOLD:.2f}'
            elif d_sig and above_eps and meets_prob and d_point < 0 and (delta_prob < 0):
                cls = 'glass_ceiling'; reason = f'Î”<0ã€æ˜¾è‘—ï¼Œ|Î”|â‰¥Îµï¼ˆ{epsilon_mode}ï¼‰ï¼Œä¸” Î”_probâ‰¥{PROB_DIFF_THRESHOLD:.2f}'
            elif d_sig and (not above_eps):
                cls = 'no_heterogeneity_small_effect'; reason = 'Î” æ˜¾è‘—ä½†æ•ˆåº”é‡ä½äºé˜ˆå€¼ Îµ'
            elif d_sig and above_eps and (not meets_prob):
                cls = 'no_heterogeneity_small_prob_effect'; reason = f'Î” æ˜¾è‘—ä¸” |Î”|â‰¥Îµï¼Œä½† Î”_prob<{PROB_DIFF_THRESHOLD:.2f}'
            elif bottom_sig_neg and top_sig_neg and not d_sig:
                cls = 'double_disadvantage'; reason = 'ä¸¤ç«¯å‡æ˜¾è‘—<0ï¼Œä½†åˆ†ä½å·®Î”ä¸æ˜¾è‘—'
            elif bottom_sig_pos and not (top_sig_neg or top_sig_pos):
                cls = 'female_advantage_bottom'; reason = 'åº•éƒ¨æ˜¾è‘—>0ï¼Œé¡¶éƒ¨ä¸æ˜¾è‘—'
            elif top_sig_pos and not (bottom_sig_neg or bottom_sig_pos):
                cls = 'female_advantage_top'; reason = 'é¡¶éƒ¨æ˜¾è‘—>0ï¼Œåº•éƒ¨ä¸æ˜¾è‘—'
            elif (not bottom_sig_neg and not bottom_sig_pos) and (not top_sig_neg and not top_sig_pos):
                cls = 'both_non_sig'; reason = 'ä¸¤ç«¯å‡ä¸æ˜¾è‘—'

            unstable_flag = (n_success / max(int(n_bootstrap), 1) < 0.6)
            warn_rate = (float(warn_counter.get('warn_count', 0)) / float(warn_counter.get('fit_count', 1)))
            high_warn = bool(warn_rate > 0.2)
            # å¯é€‰ï¼šç½®æ¢æ£€éªŒï¼ˆåœ¨ h(Y) ä¸Šå¿«é€Ÿè¿‘ä¼¼ï¼‰ï¼Œé»˜è®¤å…³é—­
            p_perm = np.nan
            if int(N_PERMUTATION_DEFAULT) > 0 and np.isfinite(d_point):
                try:
                    rng = np.random.default_rng(seed)
                    def _coef_at_tau(hy_arr, X_arr, tau):
                        try:
                            res = sm.QuantReg(hy_arr, X_arr).fit(q=float(tau), max_iter=5000, p_tol=QR_P_TOL)
                        except TypeError:
                            res = sm.QuantReg(hy_arr, X_arr).fit(q=float(tau), max_iter=5000)
                        return float(np.asarray(res.params, dtype=float)[female_idx])
                    def _delta_once(X_arr):
                        c_low = _coef_at_tau(hy, X_arr, q_low)
                        c_high = _coef_at_tau(hy, X_arr, q_high)
                        return float(c_high - c_low)
                    obs_abs = abs(float(d_point))
                    extreme = 0
                    for _ in range(int(N_PERMUTATION_DEFAULT)):
                        X_perm = np.asarray(Xg, dtype=float).copy()
                        X_perm[:, female_idx] = rng.permutation(X_perm[:, female_idx])
                        d_perm = _delta_once(X_perm)
                        if abs(d_perm) >= obs_abs:
                            extreme += 1
                    p_perm = float((extreme + 1) / (int(N_PERMUTATION_DEFAULT) + 1))
                except Exception:
                    p_perm = np.nan

            delta_row = {
                'country': str(ctry), 'n': n,
                'delta_top_bottom_point': d_point,
                'delta_top_bottom_ci_low': d_lo,
                'delta_top_bottom_ci_high': d_hi,
                'delta_top_bottom_sig': d_sig,
                'delta_top_bottom_p_boot': float(d_p),
                'delta_top_bottom_p_perm': p_perm,
                'classification': cls,
                'reason': reason,
                'delta_abs': delta_abs,
                'delta_std_sd': delta_std_sd,
                'hy_sd': hy_sd,
                'hy_iqr': hy_iqr,
                'epsilon': epsilon,
                'epsilon_mode': epsilon_mode,
                'prob_bottom_female0': prob_bottom_f0,
                'prob_bottom_female1': prob_bottom_f1,
                'prob_top_female0': prob_top_f0,
                'prob_top_female1': prob_top_f1,
                'delta_prob': delta_prob,
                'bootstrap_success_n': int(n_success),
                'bootstrap_total_n': int(n_bootstrap),
                'unstable_CI': bool(unstable_flag),
                'qr_warn_count': int(warn_counter.get('warn_count', 0)),
                'qr_fit_count': int(warn_counter.get('fit_count', 0)),
                'qr_warn_rate': warn_rate,
                'high_warn': high_warn,
                'estimand_mode': ESTIMAND_MODE,
            }
            # å°† Î” ä¿¡æ¯é‡å¤é™„åŠ åˆ°æ¯ä¸ª Ï„ çš„è¡Œï¼Œä¾¿äºç»Ÿä¸€å¯¼å‡ºä¸ç­›é€‰
            for r in [row for row in female_coef_boot_rows if row['country'] == str(ctry) and row['n'] == n]:
                r.update({k: v for k, v in delta_row.items() if k not in r})
            # å›½å®¶çº§ Î” è¡Œæ”¶é›†
            delta_rows.append(delta_row)

            # 3.2) Granularity: å¸¦åŒºèšåˆï¼ˆå‡å€¼ï¼‰ä¸ä¸‰å¯¹å¯¹æ¯”
            # å¸¦åŒºèšåˆç‚¹ä¼°
            # å…ˆæ„å»º Ï„->ç‚¹ä¼° çš„æ˜ å°„
            point_map: Dict[float, float] = {
                float(r['tau']): float(r['female_coef_point'])
                for r in female_coef_rows if r['country'] == str(ctry) and r['n'] == n and np.isfinite(r.get('female_coef_point', np.nan))
            }
            # æ„å»º Ï„->bootstrap æŠ½æ ·ï¼ˆæ¯ä¸ª Ï„ çš„ female ç³»æ•°ï¼‰
            boot_map: Dict[float, np.ndarray] = {}
            for t in TAUS_FOR_BOOT:
                samples = coef_boot.get(float(t), [])
                if samples:
                    boot_map[float(t)] = np.asarray(samples, dtype=float).reshape(-1)
            # é¢„å…ˆè®¡ç®— band å†…çš„æ¦‚ç‡å°ºåº¦ Î”_probï¼ˆä½¿ç”¨ tau_grid ä¸­è½åœ¨ band çš„ç‚¹ï¼‰
            band_to_delta_prob: Dict[str, float] = {}
            band_to_probs: Dict[str, Dict[str, float]] = {}
            # é¢„å…ˆè®¡ç®—åŸºäº hy çš„ rq_modelï¼ˆé¿å…é‡å¤æ„å»ºï¼‰
            try:
                rq_model_global = sm.QuantReg(hy, Xg)
            except Exception:
                rq_model_global = None
            # å…ˆè®¡ç®—ä¸€æ¬¡ y0_arr, y1_arrï¼ˆç”¨ 41 ç‚¹ï¼‰ï¼Œåç»­æŒ‰ band è¿‡æ»¤
            tau_grid_all = np.linspace(0.02, 0.98, 41)
            y0_arr = None; y1_arr = None
            try:
                x_rep = np.asarray(Xdf.mean(), dtype=float).reshape(-1)
                x0 = x_rep.copy(); x1 = x_rep.copy()
                x0[female_idx] = 0.0; x1[female_idx] = 1.0
                y0_list = []; y1_list = []
                if rq_model_global is not None:
                    for t in tau_grid_all:
                        try:
                            rq = rq_model_global.fit(q=float(t), max_iter=5000, p_tol=QR_P_TOL)
                        except TypeError:
                            rq = rq_model_global.fit(q=float(t), max_iter=5000)
                        b = np.asarray(rq.params, dtype=float).reshape(-1)
                        hy0 = float(x0 @ b); hy1 = float(x1 @ b)
                        y0_list.append(float(m._hinv(np.array([hy0]))[0]))
                        y1_list.append(float(m._hinv(np.array([hy1]))[0]))
                    y0_arr = np.asarray(y0_list, dtype=float)
                    y1_arr = np.asarray(y1_list, dtype=float)
            except Exception:
                y0_arr = None; y1_arr = None
            j_min = int(m._y_min_cat) if m._y_min_cat is not None else int(np.nanmin(yg))
            j_max = int(m._y_max_cat) if m._y_max_cat is not None else int(np.nanmax(yg))

            def _band_prob_metrics(low_tau: float, high_tau: float) -> Dict[str, float]:
                out = {'prob_bottom_f0': np.nan, 'prob_bottom_f1': np.nan, 'prob_top_f0': np.nan, 'prob_top_f1': np.nan, 'delta_prob': np.nan}
                if (y0_arr is None) or (y1_arr is None):
                    return out
                mask = (tau_grid_all >= float(low_tau) - 1e-12) & (tau_grid_all <= float(high_tau) + 1e-12)
                if not np.any(mask):
                    return out
                y0b = y0_arr[mask]; y1b = y1_arr[mask]; taus = tau_grid_all[mask]
                m0b = (y0b <= float(j_min) + 1e-9)
                m1b = (y1b <= float(j_min) + 1e-9)
                prob_bottom_f0 = float(np.max(taus[m0b])) if np.any(m0b) else 0.0
                prob_bottom_f1 = float(np.max(taus[m1b])) if np.any(m1b) else 0.0
                m0tcdf = (y0b <= float(j_max - 1) + 1e-9)
                m1tcdf = (y1b <= float(j_max - 1) + 1e-9)
                F0_topm1 = float(np.max(taus[m0tcdf])) if np.any(m0tcdf) else 0.0
                F1_topm1 = float(np.max(taus[m1tcdf])) if np.any(m1tcdf) else 0.0
                prob_top_f0 = float(1.0 - F0_topm1)
                prob_top_f1 = float(1.0 - F1_topm1)
                delta_prob_b = (prob_bottom_f1 - prob_bottom_f0) - (prob_top_f1 - prob_top_f0)
                out.update({'prob_bottom_f0': prob_bottom_f0, 'prob_bottom_f1': prob_bottom_f1,
                            'prob_top_f0': prob_top_f0, 'prob_top_f1': prob_top_f1,
                            'delta_prob': float(delta_prob_b)})
                return out

            # é€ band èšåˆ
            band_points: Dict[str, float] = {}
            band_draws: Dict[str, np.ndarray] = {}
            for band_name, band_taus in BANDS_DEF.items():
                taus_in_band = [float(t) for t in band_taus]
                # ç‚¹ä¼°ï¼šåŒå¸¦ Ï„ çš„å¹³å‡
                vals = [point_map.get(float(t), np.nan) for t in taus_in_band]
                vals = [v for v in vals if np.isfinite(v)]
                point_band = float(np.mean(vals)) if len(vals) > 0 else np.nan
                band_points[band_name] = point_band
                # æŠ½æ ·ï¼šå¯¹æ¯ä¸ª Ï„ çš„æŠ½æ ·å…ˆå †å ï¼Œå†æŒ‰åˆ—å¹³å‡
                sample_mats = []
                for t in taus_in_band:
                    s = boot_map.get(float(t), None)
                    if s is not None and s.size > 0:
                        sample_mats.append(s.reshape(1, -1))
                if len(sample_mats) > 0:
                    S = np.vstack(sample_mats)  # shape: (#taus_in_band, n_boot)
                    draws_band = np.nanmean(S, axis=0).reshape(-1)  # n_boot,
                else:
                    draws_band = np.array([], dtype=float)
                band_draws[band_name] = draws_band
                lo_b, hi_b, sig_b = _ci_from_samples(draws_band, level=0.95)
                p_b = _p_from_sign_two_sided(draws_band)
                # æ¦‚ç‡å°ºåº¦ï¼ˆè¯¥ band çš„ Î”_probï¼‰
                if len(band_taus) == 1:
                    low_t, high_t = float(band_taus[0]), float(band_taus[0])
                else:
                    low_t, high_t = float(min(band_taus)), float(max(band_taus))
                prob_metrics = _band_prob_metrics(low_t, high_t)
                band_to_delta_prob[band_name] = prob_metrics['delta_prob']
                band_to_probs[band_name] = prob_metrics
                band_rows.append({
                    'country': str(ctry), 'n': n, 'band': band_name,
                    'taus': ','.join([str(t) for t in taus_in_band]),
                    'female_coef_point_band': point_band,
                    'female_coef_ci_low_band': lo_b, 'female_coef_ci_high_band': hi_b,
                    'female_coef_sig_band': bool(sig_b), 'female_coef_p_boot_band': float(p_b),
                    'delta_prob_band': float(prob_metrics['delta_prob']),
                    'prob_bottom_female0_band': float(prob_metrics['prob_bottom_f0']),
                    'prob_bottom_female1_band': float(prob_metrics['prob_bottom_f1']),
                    'prob_top_female0_band': float(prob_metrics['prob_top_f0']),
                    'prob_top_female1_band': float(prob_metrics['prob_top_f1']),
                    'hy_sd': hy_sd, 'epsilon': epsilon, 'epsilon_mode': epsilon_mode,
                })

            # ä¸‰å¯¹å¯¹æ¯” + Holm æ ¡æ­£
            pair_rows_tmp = []
            for a, b in COMPARE_PAIRS:
                da = band_draws.get(a, np.array([], dtype=float))
                db = band_draws.get(b, np.array([], dtype=float))
                if da.size == 0 or db.size == 0:
                    diff_draws = np.array([], dtype=float)
                else:
                    diff_draws = (da - db).reshape(-1)
                lo_d, hi_d, sig_d = _ci_from_samples(diff_draws, level=0.95)
                p_d = _p_from_sign_two_sided(diff_draws) if diff_draws.size > 0 else np.nan
                point_d = float(band_points.get(a, np.nan) - band_points.get(b, np.nan))
                delta_prob_diff = float(band_to_delta_prob.get(a, np.nan) - band_to_delta_prob.get(b, np.nan))
                # é˜ˆå€¼åˆ¤å®š
                above_eps_pair = (np.isfinite(point_d) and np.isfinite(epsilon) and abs(point_d) >= float(epsilon))
                meets_prob_pair = (np.isfinite(delta_prob_diff) and abs(delta_prob_diff) >= float(PROB_DIFF_THRESHOLD))
                cls_pair = 'no_heterogeneity'
                reason_pair = 'è§„åˆ™æœªè§¦å‘æ˜¾è‘—å·®å¼‚'
                if sig_d and above_eps_pair and meets_prob_pair and point_d > 0 and (delta_prob_diff > 0):
                    cls_pair = f'{a}_more_sticky_vs_{b}'; reason_pair = f'{a} ç›¸å¯¹ {b} æ›´â€œåº•éƒ¨ä¸åˆ©â€ï¼ˆå‡æ»¡è¶³é˜ˆå€¼ï¼‰'
                elif sig_d and above_eps_pair and meets_prob_pair and point_d < 0 and (delta_prob_diff < 0):
                    cls_pair = f'{a}_more_glass_vs_{b}'; reason_pair = f'{a} ç›¸å¯¹ {b} æ›´â€œé¡¶éƒ¨ä¸åˆ©â€ï¼ˆå‡æ»¡è¶³é˜ˆå€¼ï¼‰'
                elif sig_d and not above_eps_pair:
                    cls_pair = 'diff_sig_but_small_effect'; reason_pair = '|å·®å€¼| ä½äº Îµ'
                elif sig_d and above_eps_pair and not meets_prob_pair:
                    cls_pair = 'diff_sig_but_small_prob_effect'; reason_pair = f'Î”_prob å·®å€¼ < {PROB_DIFF_THRESHOLD:.2f}'

                rowp = {
                    'country': str(ctry), 'n': n,
                    'band_A': a, 'band_B': b,
                    'diff_point': point_d,
                    'diff_ci_low': lo_d, 'diff_ci_high': hi_d,
                    'diff_sig': bool(sig_d), 'diff_p_boot': float(p_d) if np.isfinite(p_d) else np.nan,
                    'delta_prob_diff': delta_prob_diff,
                    'classification_pair': cls_pair,
                    'reason_pair': reason_pair,
                    'epsilon': epsilon, 'epsilon_mode': epsilon_mode,
                }
                pair_rows_tmp.append(rowp)
            # Holm æ ¡æ­£ï¼ˆæ¯å›½ 3 æ¬¡å¯¹æ¯”ï¼‰
            p_vals = [r['diff_p_boot'] for r in pair_rows_tmp if np.isfinite(r['diff_p_boot'])]
            if len(p_vals) > 0:
                m = len(pair_rows_tmp)
                # sort by p ascending
                order = sorted(range(m), key=lambda i: (pair_rows_tmp[i]['diff_p_boot'] if np.isfinite(pair_rows_tmp[i]['diff_p_boot']) else 1.0))
                p_sorted = [pair_rows_tmp[i]['diff_p_boot'] if np.isfinite(pair_rows_tmp[i]['diff_p_boot']) else 1.0 for i in order]
                p_adj_sorted = []
                for j, pj in enumerate(p_sorted, start=1):
                    p_adj_sorted.append(min((m - j + 1) * pj, 1.0))
                # enforce monotonicity
                for j in range(1, len(p_adj_sorted)):
                    p_adj_sorted[j] = max(p_adj_sorted[j], p_adj_sorted[j - 1])
                # assign back
                for idx_pos, i in enumerate(order):
                    pair_rows_tmp[i]['diff_p_boot_holm'] = float(p_adj_sorted[idx_pos])
            # åŸºäº Holm çš„æ›´ä¿å®ˆæ˜¾è‘—æ€§æ ‡è®°
            for r in pair_rows_tmp:
                r['diff_sig_holm'] = (np.isfinite(r.get('diff_p_boot_holm', np.nan)) and float(r['diff_p_boot_holm']) < 0.05)
                # æŒ‰â€œæœªæ ¡æ­£CIæ˜¾è‘— AND Holmæ˜¾è‘—â€å…±åŒä¸ºçœŸè¿›å…¥å¼ºç»“è®º
                if r['diff_sig'] and r['diff_sig_holm']:
                    pass  # åˆ†ç±»åœ¨ä¸Šæ–¹å·²ä¾æ®æœªæ ¡æ­£CIï¼›ä¿ç•™ reason_pairï¼Œä¸å¼ºæ”¹
                else:
                    # è‹¥ä»»ä¸€ä¸æ˜¾è‘—ï¼Œåˆ™è‹¥åŸåˆ†ç±»ä¸ºå¼ºç»“è®ºåˆ™é™çº§ä¸º no_heterogeneity
                    if r['classification_pair'] in (f'{a}_more_sticky_vs_{b}', f'{a}_more_glass_vs_{b}'):
                        r['classification_pair'] = 'no_heterogeneity'
                        r['reason_pair'] = 'Holm æœªé€šè¿‡æˆ– CI æœªæ˜¾è‘—'
            for r in pair_rows_tmp:
                band_compare_rows.append(r)
        else:
            warn_rate = (float(warn_counter.get('warn_count', 0)) / float(warn_counter.get('fit_count', 1)))
            delta_row = {
                'country': str(ctry), 'n': n,
                'delta_top_bottom_point': np.nan,
                'delta_top_bottom_ci_low': np.nan,
                'delta_top_bottom_ci_high': np.nan,
                'delta_top_bottom_sig': False,
                'delta_top_bottom_p_boot': np.nan,
                'classification': 'insufficient_bootstrap',
                'reason': 'Î” æ— æœ‰æ•ˆè‡ªåŠ©æ ·æœ¬',
                'bootstrap_success_n': int(n_success),
                'bootstrap_total_n': int(n_bootstrap),
                'unstable_CI': True,
                'qr_warn_count': int(warn_counter.get('warn_count', 0)),
                'qr_fit_count': int(warn_counter.get('fit_count', 0)),
                'qr_warn_rate': warn_rate,
                'high_warn': True,
                'estimand_mode': ESTIMAND_MODE,
            }
            for r in [row for row in female_coef_boot_rows if row['country'] == str(ctry) and row['n'] == n]:
                r.update({k: v for k, v in delta_row.items() if k not in r})
            # å›½å®¶çº§ Î” è¡Œæ”¶é›†
            delta_rows.append(delta_row)

    female_coef_df = pd.DataFrame(female_coef_rows)
    female_coef_ci_df = pd.DataFrame(female_coef_boot_rows)
    female_coef_all = (
        female_coef_df.merge(
            female_coef_ci_df,
            on=['country', 'n', 'tau'],
            how='outer'
        ).sort_values(['country', 'tau'])
    )
    # ç»Ÿä¸€åˆ—åï¼šåˆå¹¶åå¯èƒ½å‡ºç° female_coef_point_x / female_coef_point_y
    if 'female_coef_point_x' in female_coef_all.columns or 'female_coef_point_y' in female_coef_all.columns:
        # ä¼˜å…ˆä½¿ç”¨ç‚¹ä¼°æ¥æºï¼ˆ_xï¼‰ï¼Œç¼ºå¤±æ—¶ç”¨ CI è¡¨ä¸­çš„å›å¡«ï¼ˆ_yï¼‰
        female_coef_all['female_coef_point'] = female_coef_all.get('female_coef_point_x')
        if 'female_coef_point_y' in female_coef_all.columns:
            female_coef_all['female_coef_point'] = female_coef_all['female_coef_point'].fillna(
                female_coef_all['female_coef_point_y']
            )
        drop_cols = [c for c in ['female_coef_point_x', 'female_coef_point_y'] if c in female_coef_all.columns]
        female_coef_all = female_coef_all.drop(columns=drop_cols)
    return female_coef_all, pd.DataFrame(delta_rows), pd.DataFrame(band_rows), pd.DataFrame(band_compare_rows)

_log(f"[2/3] å¼€å§‹åˆ†å›½å®¶ç³»æ•°åˆ†æ (min_n=500, bootstrap={N_BOOTSTRAP_DEFAULT})â€¦")
female_coef_all, delta_df, band_df, band_cmp_df = analyze_by_country_detailed(min_n=500, n_bootstrap=N_BOOTSTRAP_DEFAULT)

print(f"\nå®Œæˆï¼æ¶µç›– {female_coef_all['country'].nunique() if len(female_coef_all) > 0 else 0} ä¸ªå›½å®¶")
print("\n=== being female çš„åˆ†ä½ç³»æ•°ï¼ˆå‰10è¡Œï¼‰===")
print(female_coef_all.head(10))

# ==================== Step 4: å¯¼å‡ºä¸å¯è§†åŒ– ====================
_log("[3/3] å¯¼å‡º CSV å¹¶ç»˜åˆ¶ç³»æ•°â€”åˆ†ä½ç‚¹æ›²çº¿å›¾â€¦")
if len(female_coef_all) > 0:
    out_csv = f'{OUTPUT_DIR}/female_coef_by_quantile.csv'
    female_coef_all.to_csv(out_csv, index=False)
    print(f"âœ“ åˆ†ä½ç³»æ•°è¡¨ï¼ˆfemale + CIï¼‰å·²ä¿å­˜: {out_csv}")
    # è¾“å‡ºå›½å®¶çº§æ±‡æ€»ï¼ˆÎ” ä¸åˆ†ç±» + è¯Šæ–­ï¼‰ï¼Œç›´æ¥ç”¨ delta_dfï¼Œç¡®ä¿æ—  CI å›½å®¶ä¹Ÿæœ‰åˆ†ç±»
    keep_cols = ['country', 'n',
                 'delta_top_bottom_point', 'delta_abs', 'delta_std_sd', 'delta_prob',
                 'prob_bottom_female0', 'prob_bottom_female1', 'prob_top_female0', 'prob_top_female1',
                 'delta_top_bottom_ci_low', 'delta_top_bottom_ci_high',
                 'delta_top_bottom_sig', 'delta_top_bottom_p_boot', 'delta_top_bottom_p_perm',
                 'classification', 'reason',
                 'hy_sd', 'hy_iqr', 'epsilon', 'epsilon_mode',
                 'bootstrap_success_n', 'bootstrap_total_n', 'unstable_CI',
                 'qr_warn_count', 'qr_fit_count', 'qr_warn_rate', 'high_warn',
                 'estimand_mode']
    summary_df = delta_df.reindex(columns=[c for c in keep_cols if c in delta_df.columns])
    out_csv2 = f'{OUTPUT_DIR}/female_coef_summary_by_country.csv'
    summary_df.to_csv(out_csv2, index=False)
    print(f"âœ“ å›½å®¶çº§æ±‡æ€»ï¼ˆÎ” ä¸åˆ†ç±»ï¼‰å·²ä¿å­˜: {out_csv2}")
    # è¾“å‡ºå¸¦åŒºèšåˆä¸å¯¹æ¯”ç»“æœ
    if len(band_df) > 0:
        out_csv3 = f'{OUTPUT_DIR}/female_coef_bands.csv'
        band_df.to_csv(out_csv3, index=False)
        print(f"âœ“ å¸¦åŒºèšåˆç»“æœå·²ä¿å­˜: {out_csv3}")
    if len(band_cmp_df) > 0:
        out_csv4 = f'{OUTPUT_DIR}/female_coef_band_comparisons.csv'
        band_cmp_df.to_csv(out_csv4, index=False)
        print(f"âœ“ å¸¦åŒºå¯¹æ¯”ç»“æœå·²ä¿å­˜: {out_csv4}")
        # ç”Ÿæˆå†™ä½œå‹å¥½çš„â€œå¸¦åŒºå¯¹æ¯”æ¦‚è§ˆâ€å®½è¡¨ï¼ˆé™„å½•ç”¨ï¼‰
        try:
            cols_view = ['country','band_A','band_B','diff_point','diff_ci_low','diff_ci_high','diff_p_boot_holm','delta_prob_diff','classification_pair']
            view_df = band_cmp_df.reindex(columns=[c for c in cols_view if c in band_cmp_df.columns]).copy()
            # å¯æŒ‰å›½å®¶é€è§†ä¸ºå¤šåˆ—ï¼ˆå¯åœ¨åå¤„ç†ä¸­ç»§ç»­ç¾åŒ–ï¼‰ï¼Œæ­¤å¤„å…ˆç›´æ¥å¯¼å‡ºé•¿è¡¨è§†å›¾
            out_csv5 = f'{OUTPUT_DIR}/female_coef_band_comparisons_view.csv'
            view_df.to_csv(out_csv5, index=False)
            print(f"âœ“ å¸¦åŒºå¯¹æ¯”æ¦‚è§ˆï¼ˆé•¿è¡¨ï¼‰å·²ä¿å­˜: {out_csv5}")
        except Exception:
            pass
    print("[note] é™„æ³¨ï¼šqr_warn_rate > 0.2 è§†ä¸ºä¸ç¨³å®šï¼ˆhigh_warn=Trueï¼‰ã€‚")

    # ç”»æ¯å›½ä¸€æ¡æ›²çº¿ï¼Œå¹¶ç”¨é˜´å½±æ ‡å‡º 95% CI
    plt.figure(figsize=(7, 5))
    for ctry, g in female_coef_all.groupby('country'):
        g = g.sort_values('tau')
        plt.plot(g['tau'], g['female_coef_point'], label=str(ctry))
        if {'female_coef_ci_low', 'female_coef_ci_high'}.issubset(g.columns):
            mask = g[['female_coef_ci_low','female_coef_ci_high']].notna().all(axis=1)
            if mask.any():
                plt.fill_between(g.loc[mask, 'tau'], g.loc[mask, 'female_coef_ci_low'], g.loc[mask, 'female_coef_ci_high'], alpha=0.15)
    plt.axhline(0.0, linestyle='--', linewidth=1)
    plt.xlabel('Quantile (Ï„)')
    ylabel = 'Coef of being female (on h(Y) scale)' if ESTIMAND_MODE=='single_index' else 'Linearized coef of being female on final combo u_Ï„'
    plt.ylabel(ylabel)
    # å–ä¸ bootstrap åŒ¹é…çš„åº•/é¡¶åˆ†ä½ç”¨äºæ ‡é¢˜è¯´æ˜
    q_low, q_high = (min(QUANTILES_MAIN), max(QUANTILES_MAIN))
    plt.title(f'Female effect across quantiles (95% CI at Ï„={q_low}, {q_high})')
    plt.legend(fontsize=8)
    plt.tight_layout()
    fig_path = f'{OUTPUT_DIR}/female_coef_curve.png'
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    if SHOW_FIG:
        plt.show()
    else:
        plt.close()
    print(f"âœ“ ç³»æ•°æ›²çº¿å›¾å·²ä¿å­˜: {fig_path}")
else:
    print("æ— å¯å¯¼å‡ºçš„ç³»æ•°ç»“æœã€‚")

# ç®€æ˜é˜…è¯»å£å¾„ï¼ˆç”¨äºè®ºæ–‡/æŠ¥å‘Šï¼‰
print("\nâ€”â€” å¦‚ä½•åˆ¤è¯»ï¼š")
print("- åº•éƒ¨ Ï„=0.2 æ˜¾è‘—<0ã€é¡¶éƒ¨ Ï„=0.8 â‰ˆ0 â†’ sticky floor")
print("- é¡¶éƒ¨ Ï„=0.8 æ˜¾è‘—<0ã€åº•éƒ¨ Ï„=0.2 â‰ˆ0 â†’ glass ceiling")
print("- ä¸¤ç«¯å‡æ˜¾è‘—<0 â†’ double disadvantageï¼›åŒºé—´è¦†ç›–0 â†’ æ— æ˜¾è‘—åˆ†ä½å¼‚è´¨æ€§")

print("\nğŸ¯ æ ¸å¿ƒæ–¹æ³•æç¤ºï¼šæœ¬è„šæœ¬ç›´æ¥ç”¨ â€œbeing female çš„åˆ†ä½ç³»æ•° + bootstrap CIâ€ éªŒè¯ sticky floor / glass ceilingã€‚" )
print("- è®¾è®¡çŸ©é˜µæ— æˆªè·ï¼šç³»æ•°ä¸ºç›¸å¯¹æ— æˆªè·åŸºå‡†çš„è¾¹é™…æ•ˆåº”ï¼›Î” åˆ¤å®šä¸å—å½±å“ï¼Œä»…éœ€è¯´æ˜ã€‚")
print("- æ¦‚ç‡å°ºåº¦ä¸ºè¿‘ä¼¼ï¼šé€šè¿‡ Ï„â†’h(Y)â†’h^{-1}(Â·)â†’ç±»åˆ«é˜ˆå€¼ çš„ç¦»æ•£è¿‘ä¼¼å¾—åˆ°åº•/é¡¶æ¦‚ç‡å·® Î”_probï¼Œä¾¿äºå¯è§£é‡Šæ€§ã€‚")

