import pandas as pd
import numpy as np
import os as _os, sys as _sys, math
# ç¡®ä¿å¯ä»¥ä»¥ç»å¯¹æ–¹å¼å¯¼å…¥ `glm_plus`ï¼ˆæŠŠé¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼‰
_PROJECT_ROOT = _os.path.abspath(_os.path.join(_os.path.dirname(__file__), '..'))
if _PROJECT_ROOT not in _sys.path:
    _sys.path.insert(0, _PROJECT_ROOT)
from glm_plus.frequentist_version.torque import FrequentistOQR
from matplotlib import pyplot as plt
from typing import Dict, Tuple

# ==================== å¸¸é‡ä¸é…ç½®ï¼ˆå…¨å±€å”¯ä¸€ï¼‰ ====================
# åˆ†ä½ç‚¹é›†åˆ
QUANTILES_MAIN = (0.2, 0.5, 0.8)
ALL_QUANTILES = QUANTILES_MAIN
BOTTOM_QUANTILES = {0.2}
TOP_QUANTILES = {0.8}
ORDER_LABELS = ["Assistant/Junior", "Regular", "Leader", "Chief/Founder"]

def _pos_of_tau(t: float) -> str:
    return 'bottom' if t <= 0.3 else ('top' if t >= 0.7 else 'middle')

# ç®€å•è¿›åº¦æ—¥å¿—å‡½æ•°
def _log(msg: str) -> None:
    print(f"[Progress] {msg}")

# subsample è§„åˆ™
SUBSAMPLE_RULE = lambda n: (min(n, 5000) if n > 20000 else (min(n, 3000) if n > 2000 else None))

# è¾“å‡ºç›®å½•
import os
OUTPUT_DIR = "output_results"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ç»Ÿä¸€æ‹Ÿåˆå‡½æ•°ï¼šé‡åŒ–é…ç½®åœ¨ä¸€å¤„ç®¡ç†
def fit_model(X: np.ndarray, y: np.ndarray, taus=QUANTILES_MAIN, random_state: int = 0, use_two_index: bool = False) -> FrequentistOQR:
    # æœ€å°æ”¹æ³•ï¼šæ¯å›½åªæ‹Ÿåˆä¸€æ¬¡ + é™ä½ç½‘æ ¼/å­æ ·æœ¬æå‡é€Ÿåº¦ï¼›å›ºå®šå•æŒ‡æ•°
    m = FrequentistOQR(
        quantiles=taus,
        use_two_index=False,
        auto_select_k=True,
        subsample_n=2000,
        rank_grid_n=31,
        t_grid_n=41,
        random_state=random_state,
    )
    m.fit(X, y)
    return m

# ==================== Step 1: è¯»å–æ•°æ®ï¼ˆä»…ç”¨äºåç»­åˆ†å›½å®¶åˆ†æï¼‰ ====================
_log("[1/4] è¯»å–æ•°æ®...")
_DATA_DIR = _os.path.dirname(__file__)
_CSV_PATH = _os.path.join(_DATA_DIR, "df_seniority.csv")
assert _os.path.exists(_CSV_PATH), f"æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {_CSV_PATH}"
df_seniority = pd.read_csv(_CSV_PATH)
_log("[1/4] æ•°æ®åŠ è½½å®Œæˆ")

# æœ€åŸºæœ¬çš„æ•°æ®åˆ—æ£€æŸ¥
assert 'country' in df_seniority.columns, "df_seniority éœ€è¦åŒ…å« 'country' åˆ—"

# æŒ‰å›½å®¶åˆ†ç»„è¯„ä¼°â€œç²˜åœ°æ¿/ç»ç’ƒå¤©èŠ±æ¿â€
# ä»…ä¿ç•™ç”¨äºæ„å»ºè®¾è®¡çŸ©é˜µçš„å‡½æ•°ï¼Œå…¶å®ƒæ—§è¯„ä¼°å‡½æ•°å·²ç”±æ–°ç‰ˆè¦†ç›–

def build_design_for_subset(df_sub: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, np.ndarray, np.ndarray]:
    cols_needed = [
        'gender', 'highest_educational_degree',
        'whether_bachelor_university_prestigious',
        'internationalization', 'work_years', 'company_size', 'Y10'
    ]
    d = df_sub[cols_needed].dropna().copy()
    # y
    cat_type = pd.CategoricalDtype(categories=ORDER_LABELS, ordered=True)
    d['y_cat'] = d['Y10'].astype(cat_type)
    # è¿‡æ»¤ä¸åœ¨å·²çŸ¥æ ‡ç­¾å†…çš„è®°å½•ï¼Œé¿å… y ç¼–ç ä¸º 0
    d = d[~d['y_cat'].isna()].copy()
    d['y'] = d['y_cat'].cat.codes + 1
    # female
    gg = d['gender'].astype(str).str.strip().str.lower()
    d['female'] = (gg == 'female').astype(int)
    # prestige
    col_p = 'whether_bachelor_university_prestigious'
    if str(d[col_p].dtype) == 'bool':
        d['prestigious_bachelor'] = d[col_p].astype(int)
    else:
        d['prestigious_bachelor'] = (
            d[col_p].astype(str).str.strip().str.lower().isin(['true','1','yes','y','t'])
        ).astype(int)
    # numeric
    d['work_years'] = pd.to_numeric(d['work_years'], errors='coerce')
    d = d.dropna(subset=['work_years']).copy()
    # one-hot
    cat_cols = ['highest_educational_degree', 'internationalization', 'company_size']
    X_cat = pd.get_dummies(d[cat_cols], columns=cat_cols, drop_first=True, dtype=int)
    X_df = pd.concat([
        d[['female', 'prestigious_bachelor', 'work_years']].reset_index(drop=True),
        X_cat.reset_index(drop=True)
    ], axis=1)
    X = X_df.to_numpy(dtype=float)
    y = d['y'].to_numpy(dtype=int)
    return d, X_df, X, y

 

# ==================== å‡½æ•°æå‰å‡†å¤‡å¥½ï¼šå†™å¥½å‡½æ•°çš„æ€§åˆ«å·®ï¼ˆåº•/ä¸­/é¡¶ï¼‰====================

def compute_gender_gaps_at_key_quantiles(model: FrequentistOQR, X_df_in: pd.DataFrame, 
                                        quantiles=QUANTILES_MAIN) -> Dict:
    """
    å›ºå®šåå˜é‡åœ¨å…¸å‹å€¼ï¼Œåªåˆ‡æ¢æ€§åˆ«ï¼Œè®¡ç®—å„åˆ†ä½ç‚¹çš„female-maleå·®å¼‚
    è¿”å›è¯¦ç»†ç»“æœå­—å…¸
    """
    # æ„é€ ä»£è¡¨æ€§ä¸ªä½“ï¼šè¿ç»­å˜é‡å–ä¸­ä½æ•°ï¼Œç±»åˆ«å˜é‡å–åŸºå‡†ç±»(å…¨0)
    ref = {c: 0.0 for c in X_df_in.columns}
    ref['female'] = 0.0  # ç”·æ€§åŸºå‡†
    if 'prestigious_bachelor' in X_df_in:
        ref['prestigious_bachelor'] = float(X_df_in['prestigious_bachelor'].median())
    if 'work_years' in X_df_in:
        ref['work_years'] = float(X_df_in['work_years'].median())
    
    # ç”·æ€§å’Œå¥³æ€§çš„é¢„æµ‹
    X_male = pd.DataFrame([ref])
    X_female = pd.DataFrame([ref]); X_female['female'] = 1.0
    
    pred_male = model.predict_quantiles_continuous(X_male.to_numpy(dtype=float), quantiles=quantiles)
    pred_female = model.predict_quantiles_continuous(X_female.to_numpy(dtype=float), quantiles=quantiles)
    
    # è®¡ç®—å·®å¼‚ï¼šfemale - maleï¼ˆè´Ÿå€¼è¡¨ç¤ºå¥³æ€§é¢„æµ‹æ›´ä½ï¼Œå³å¤„å¢ƒæ›´å·®ï¼‰
    gaps = {}
    for tau in quantiles:
        male_val = float(np.asarray(pred_male[tau], dtype=float).reshape(-1)[0])
        female_val = float(np.asarray(pred_female[tau], dtype=float).reshape(-1)[0])
        gap = female_val - male_val
        gaps[tau] = {
            'quantile': tau,
            'male_pred': male_val,
            'female_pred': female_val, 
            'gap_female_minus_male': gap,
            'position': _pos_of_tau(tau)
        }
    
    # åˆ¤åˆ«ç²˜åœ°æ¿vsç»ç’ƒå¤©èŠ±æ¿
    bottom_gap = float(gaps[0.2]['gap_female_minus_male']) if 0.2 in gaps else np.nan
    top_gap = float(gaps[0.8]['gap_female_minus_male']) if 0.8 in gaps else np.nan
    
    conclusion = 'glass ceiling' if abs(top_gap) > abs(bottom_gap) else 'sticky floor'
    gap_diff = bottom_gap - top_gap  # æ­£å€¼å€¾å‘sticky floor
    
    return {
        'gaps_by_quantile': gaps,
        'bottom_gap_avg': bottom_gap,
        'top_gap_avg': top_gap, 
        'gap_diff_bottom_minus_top': gap_diff,
        'conclusion': conclusion,
        'reference_profile': dict(ref)
    }

# ==================== å‡½æ•°æå‰å‡†å¤‡å¥½ï¼šç¦»ä¸‹ä¸€é—¨æ§›çš„è·ç¦»ï¼ˆä¸­ç‚¹æ³•ï¼‰ ====================

def compute_threshold_distances(model: FrequentistOQR, X: np.ndarray, y: np.ndarray, 
                               X_df: pd.DataFrame, quantiles=ALL_QUANTILES, non_negative: bool = False) -> Dict:
    """
    è®¡ç®—æ¯ä¸ªä¸ªä½“åœ¨å„åˆ†ä½ç‚¹ç¦»ä¸‹ä¸€é—¨æ§›çš„è·ç¦»ï¼Œå¹¶åˆ†ææ€§åˆ«å·®å¼‚
    - å½“å‰çº§åˆ«ä½¿ç”¨è§‚æµ‹ y_true è€Œéé¢„æµ‹floor
    - non_negative=True åˆ™å¯¹è·ç¦»åšéè´Ÿæˆªæ–­
    """
    pred_cont = model.predict_quantiles_continuous(X, quantiles=quantiles)
    results = {}
    for tau in quantiles:
        y_pred_cont = pred_cont[tau]
        distances, current_levels, target_levels = [], [], []
        for y_pred, y_true_i in zip(y_pred_cont, y):
            current_level = int(np.clip(y_true_i, 1, 4))
            if current_level >= 4:
                distances.append(np.nan); current_levels.append(current_level); target_levels.append(np.nan)
                continue
            # ä¸­ç‚¹æ³•ï¼šæŠŠç›¸é‚»ç±»åˆ« j ä¸ j+1 çš„è¾¹ç•Œå®šä¹‰ä¸º j+0.5
            boundary = current_level + 0.5
            d_raw = float(boundary - y_pred)
            d_use = max(0.0, d_raw) if non_negative else d_raw
            distances.append(d_use)
            current_levels.append(current_level)
            target_levels.append(current_level + 1)
        df_dist = pd.DataFrame({
            'y_pred_cont': y_pred_cont,
            'y_true': y,
            'current_level': current_levels,
            'target_level': target_levels,
            'distance_to_next': distances,
            'female': X_df['female'].values if 'female' in X_df.columns else 0
        })
        df_valid = df_dist.dropna(subset=['distance_to_next'])
        if len(df_valid) > 0:
            gender_distances = df_valid.groupby('female')['distance_to_next'].agg(['mean', 'std', 'count']).reset_index()
            gender_distances['gender'] = gender_distances['female'].map({0: 'male', 1: 'female'})
            if len(gender_distances) == 2:
                male_dist = gender_distances.loc[gender_distances['gender']=='male','mean'].iloc[0]
                female_dist = gender_distances.loc[gender_distances['gender']=='female','mean'].iloc[0]
                gap = float(female_dist - male_dist)
            else:
                male_dist = female_dist = gap = np.nan
        else:
            gender_distances = pd.DataFrame()
            male_dist = female_dist = gap = np.nan
        results[tau] = {
            'quantile': tau,
            'position': _pos_of_tau(tau),
            'data': df_dist,
            'gender_summary': gender_distances,
            'male_avg_distance': male_dist,
            'female_avg_distance': female_dist,
            'gap_female_minus_male': gap
        }
    return results


# éšæœºä»£è¡¨äººå¹³å‡å·®ï¼šä»çœŸå®åå˜é‡åˆ†å¸ƒä¸­éšæœºæŠ½æ ·ï¼Œè®¡ç®—å¹³å‡æ€§åˆ«å·®
def compute_average_gaps_over_random_references(
    model: FrequentistOQR,
    X_df_in: pd.DataFrame,
    n_samples: int = 1000,
    random_state: int = 0,
    quantiles = ALL_QUANTILES,
) -> Dict[float, float]:
    rng = np.random.RandomState(random_state)
    if len(X_df_in) == 0:
        return {tau: np.nan for tau in quantiles}
    sample_size = int(min(n_samples, len(X_df_in)))
    idx = rng.choice(len(X_df_in), size=sample_size, replace=True)
    X_sample = X_df_in.iloc[idx].copy()
    X_male = X_sample.copy(); X_male['female'] = 0.0
    X_female = X_sample.copy(); X_female['female'] = 1.0
    pred_male = model.predict_quantiles_continuous(X_male.to_numpy(dtype=float), quantiles=quantiles)
    pred_female = model.predict_quantiles_continuous(X_female.to_numpy(dtype=float), quantiles=quantiles)
    avg_gaps = {}
    for tau in quantiles:
        male_vals = np.asarray(pred_male[tau], dtype=float)
        female_vals = np.asarray(pred_female[tau], dtype=float)
        avg_gaps[tau] = float(np.nanmean(female_vals - male_vals))
    return avg_gaps


# ==================== Step 2: æŒ‰å›½å®¶åˆ†ç»„åˆ†æ ====================

def analyze_by_country_detailed(min_n: int = 500, n_bootstrap: int = 500, random_state: int = 0) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    æŒ‰å›½å®¶è¿›è¡Œå®Œæ•´çš„æ€§åˆ«å·®å’Œé—¨æ§›è·ç¦»åˆ†æ
    è¿”å›ä¸¤ä¸ªæ±‡æ€»è¡¨ï¼šgender_gap_summary, threshold_distance_summary
    """
    gap_rows = []
    threshold_rows = []
    avg_refs_rows = []
    boot_summary_rows = []
    
    print("=== æŒ‰å›½å®¶åˆ†æè¿›åº¦ ===")
    for ctry, df_g in df_seniority.groupby('country'):
        d, Xdf, Xg, yg = build_design_for_subset(df_g)
        n = len(yg)
        if n < min_n:
            print(f"{ctry}: è·³è¿‡ (n={n} < {min_n})")
            continue
        
        print(f"{ctry}: åˆ†æä¸­ (n={n})...")
        
        # æ‹Ÿåˆæ¨¡å‹ï¼ˆä¸€æ¬¡æ‹Ÿåˆï¼‰
        m = fit_model(Xg, yg, taus=QUANTILES_MAIN, random_state=0, use_two_index=False)
        # Bootstrap æ¨æ–­ï¼šå›ºå®š h/gï¼Œä»…å¯¹ QR é‡ä¼°ï¼ˆè¿”å›ç³»æ•°æŠ½æ ·ï¼‰
        try:
            boot = m.bootstrap_inference(n_boot=n_bootstrap, return_coefs=True)
            female_idx = int(Xdf.columns.get_loc('female')) if 'female' in Xdf.columns else None
            if female_idx is not None:
                b1_ci_lo = float(np.asarray(boot['beta1']['ci_low'])[female_idx])
                b1_ci_hi = float(np.asarray(boot['beta1']['ci_high'])[female_idx])
                b1_ci_level = float(boot['beta1'].get('ci_level', 0.95))
                b1_sig = not (b1_ci_lo <= 0.0 <= b1_ci_hi)
                # è¿‘ä¼¼ p å€¼ï¼ˆæ­£æ€è¿‘ä¼¼ï¼‰ï¼šz = coef / se
                female_coef = float(m.beta1_[female_idx]) if getattr(m, 'beta1_', None) is not None else np.nan
                female_se = float(np.asarray(boot['beta1']['se'])[female_idx])
                if np.isfinite(female_coef) and np.isfinite(female_se) and female_se > 0:
                    z = abs(female_coef / female_se)
                    b1_p = float(math.erfc(z / math.sqrt(2.0)))
                else:
                    b1_p = np.nan
            else:
                b1_ci_lo = b1_ci_hi = np.nan
                b1_ci_level = 0.95
                b1_sig = False
                b1_p = np.nan
        except Exception as _e:
            b1_ci_lo = b1_ci_hi = np.nan
            b1_ci_level = 0.95
            b1_sig = False
            b1_p = np.nan
        
        # æ€§åˆ«å·®åˆ†æï¼ˆåŸºå‡†ä»£è¡¨äººï¼‰
        gaps = compute_gender_gaps_at_key_quantiles(m, Xdf)
        for tau in ALL_QUANTILES:
            gap_info = gaps['gaps_by_quantile'][tau]
            gap_rows.append({
                'country': str(ctry),
                'n': n,
                'quantile': tau,
                'position': gap_info['position'],
                'male_pred': gap_info['male_pred'],
                'female_pred': gap_info['female_pred'],
                'gap_female_minus_male': gap_info['gap_female_minus_male'],
                'female_ci_low_b1_q50': b1_ci_lo,
                'female_ci_high_b1_q50': b1_ci_hi,
                'female_sig_b1_q50': b1_sig,
                'female_se_b1_q50': female_se if 'female_se' in locals() else np.nan,
                'female_p_b1_q50': b1_p,
                'ci_level': b1_ci_level
            })

        # é¡¶éƒ¨å·®/åº•éƒ¨å·®ï¼ˆç‚¹ä¼°ï¼ŒæŒ‰ä»£è¡¨äººï¼‰
        bottom_gap_point = float(gaps['gaps_by_quantile'][0.2]['gap_female_minus_male']) if 0.2 in gaps['gaps_by_quantile'] else np.nan
        top_gap_point = float(gaps['gaps_by_quantile'][0.8]['gap_female_minus_male']) if 0.8 in gaps['gaps_by_quantile'] else np.nan
        diff_abs_point = float(abs(top_gap_point) - abs(bottom_gap_point)) if np.isfinite(bottom_gap_point) and np.isfinite(top_gap_point) else np.nan
        
        # é—¨æ§›è·ç¦»åˆ†æ
        thresh_results = compute_threshold_distances(m, Xg, yg, Xdf)
        for tau in ALL_QUANTILES:
            thresh_info = thresh_results[tau]
            threshold_rows.append({
                'country': str(ctry),
                'n': n,
                'quantile': tau,
                'position': thresh_info['position'],
                'male_avg_distance': thresh_info['male_avg_distance'],
                'female_avg_distance': thresh_info['female_avg_distance'],
                'gap_female_minus_male': thresh_info['gap_female_minus_male']
            })

        # éšæœºä»£è¡¨äººå¹³å‡å·®ï¼ˆé¢å¤–ç¨³å¥æ€§ï¼‰
        avg_gaps = compute_average_gaps_over_random_references(m, Xdf, n_samples=1000, random_state=random_state)
        avg_bottom = float(avg_gaps.get(0.2, np.nan))
        avg_top = float(avg_gaps.get(0.8, np.nan))
        avg_diff_abs_point = float(abs(avg_top) - abs(avg_bottom)) if np.isfinite(avg_bottom) and np.isfinite(avg_top) else np.nan
        avg_refs_rows.append({
            'country': str(ctry),
            'n': n,
            'avg_bottom_gap_random_refs': avg_bottom,
            'avg_top_gap_random_refs': avg_top,
            'conclusion_random_refs': ('glass ceiling' if abs(avg_top) > abs(avg_bottom) else 'sticky floor')
        })

        # Bootstrap é¡¶éƒ¨å·®âˆ’åº•éƒ¨å·®ï¼šä½¿ç”¨ç³»æ•°æŠ½æ ·ï¼ˆfemale ç³»æ•°åœ¨ h(Y) çš„ QR ä¸­å¯¹æ‰€æœ‰ X æ’ç­‰äºç³»æ•°æœ¬èº«ï¼‰
        boot_diff_abs = []
        boot_avg_diff_abs = []
        try:
            female_idx2 = int(Xdf.columns.get_loc('female')) if 'female' in Xdf.columns else None
            if female_idx2 is not None:
                draws_low = boot.get('beta_tau', {}).get(0.2, {}).get('draws', None)
                draws_top = boot.get('beta_tau', {}).get(0.8, {}).get('draws', None)
                if draws_low is not None and draws_top is not None:
                    low_f = np.asarray(draws_low)[:, female_idx2]
                    top_f = np.asarray(draws_top)[:, female_idx2]
                    boot_diff_abs = list(np.abs(top_f) - np.abs(low_f))
                    # å¹³å‡ä»£è¡¨äººå·®åŒæ ·ç­‰äº female ç³»æ•°ï¼Œå› æ­¤ä¸ä¸Šè€…ç›¸åŒ
                    boot_avg_diff_abs = list(np.abs(top_f) - np.abs(low_f))
        except Exception:
            boot_diff_abs = []
            boot_avg_diff_abs = []

        def _ci_and_sig(samples: list[float], level: float = 0.95) -> tuple[float, float, bool]:
            if not samples:
                return (np.nan, np.nan, False)
            arr = np.asarray(samples, dtype=float)
            lo = float(np.nanpercentile(arr, (1.0 - level) / 2.0 * 100.0))
            hi = float(np.nanpercentile(arr, (1.0 + level) / 2.0 * 100.0))
            sig = not (lo <= 0.0 <= hi)
            return (lo, hi, sig)

        def _p_from_sign(samples: list[float]) -> float:
            if not samples:
                return float('nan')
            arr = np.asarray(samples, dtype=float)
            p = 2.0 * float(min(np.mean(arr <= 0.0), np.mean(arr >= 0.0)))
            return float(min(max(p, 0.0), 1.0))

        diff_abs_lo, diff_abs_hi, diff_abs_sig = _ci_and_sig(boot_diff_abs, level=0.95)
        avg_diff_abs_lo, avg_diff_abs_hi, avg_diff_abs_sig = _ci_and_sig(boot_avg_diff_abs, level=0.95)
        diff_abs_p = _p_from_sign(boot_diff_abs)
        avg_diff_abs_p = _p_from_sign(boot_avg_diff_abs)

        boot_summary_rows.append({
            'country': str(ctry),
            'n': n,
            'diff_abs_top_minus_bottom_point': diff_abs_point,
            'diff_abs_top_minus_bottom_ci_low': diff_abs_lo,
            'diff_abs_top_minus_bottom_ci_high': diff_abs_hi,
            'diff_abs_top_minus_bottom_sig': diff_abs_sig,
            'diff_abs_top_minus_bottom_p': diff_abs_p,
            'avg_diff_abs_top_minus_bottom_point': avg_diff_abs_point,
            'avg_diff_abs_top_minus_bottom_ci_low': avg_diff_abs_lo,
            'avg_diff_abs_top_minus_bottom_ci_high': avg_diff_abs_hi,
            'avg_diff_abs_top_minus_bottom_sig': avg_diff_abs_sig,
            'avg_diff_abs_top_minus_bottom_p': avg_diff_abs_p,
            'ci_level': 0.95
        })
    
    gap_df = pd.DataFrame(gap_rows)
    threshold_df = pd.DataFrame(threshold_rows)
    avg_refs_df = pd.DataFrame(avg_refs_rows)
    boot_summary_df = pd.DataFrame(boot_summary_rows)
    
    return gap_df, threshold_df, avg_refs_df, boot_summary_df

_log("[2/4] å¼€å§‹åˆ†å›½å®¶åˆ†æ (min_n=500, bootstrap=500)...")
country_gaps_df, country_thresholds_df, avg_refs_df, boot_summary_df = analyze_by_country_detailed(min_n=500, n_bootstrap=500)

print(f"\nå®Œæˆï¼æ¶µç›– {country_gaps_df['country'].nunique()} ä¸ªå›½å®¶")
print("\n=== æ€§åˆ«å·®æ±‡æ€»ï¼ˆå‰10è¡Œï¼‰===")
print(country_gaps_df.head(10))

print("\n=== é—¨æ§›è·ç¦»æ±‡æ€»ï¼ˆå‰10è¡Œï¼‰===")
print(country_thresholds_df.head(10))
print("\n=== éšæœºä»£è¡¨äººå¹³å‡å·®ï¼ˆå‰10è¡Œï¼‰===")
print(avg_refs_df.head(10))
print("\n=== é¡¶éƒ¨å·®âˆ’åº•éƒ¨å·®ï¼ˆå«CIï¼Œå‰10è¡Œï¼‰===")
print(boot_summary_df.head(10))

_log("[3/4] ç”Ÿæˆå›¾è¡¨...")
fig, axes = plt.subplots(1, 2, figsize=(14, 6))
fig.suptitle('Gender Gap Analysis by Country (Two Heatmaps)', fontsize=16)

# å·¦å›¾ï¼šæŒ‰å›½å®¶çš„æ€§åˆ«å·®çƒ­å›¾
ax_left = axes[0]
if len(country_gaps_df) > 0:
    pivot_gaps = country_gaps_df.pivot(index='country', columns='quantile', values='gap_female_minus_male')
    im1 = ax_left.imshow(pivot_gaps.values, aspect='auto', cmap='RdBu_r', vmin=-0.5, vmax=0.5)
    ax_left.set_xticks(range(len(pivot_gaps.columns)))
    ax_left.set_xticklabels([f'Ï„={tau:.1f}' for tau in pivot_gaps.columns])
    ax_left.set_yticks(range(len(pivot_gaps.index)))
    ax_left.set_yticklabels(pivot_gaps.index, fontsize=8)
    ax_left.set_title('Gender Gap by Country (Female - Male)')
    ax_left.set_xlabel('Quantile')
    plt.colorbar(im1, ax=ax_left, label='Gap')
else:
    ax_left.text(0.5, 0.5, 'No country data available', ha='center', va='center')
    ax_left.set_title('Gender Gap by Country')

# å³å›¾ï¼šæŒ‰å›½å®¶çš„é—¨æ§›è·ç¦»çƒ­å›¾
ax_right = axes[1]
if len(country_thresholds_df) > 0:
    pivot_thresholds = country_thresholds_df.pivot(index='country', columns='quantile', values='gap_female_minus_male')
    im2 = ax_right.imshow(pivot_thresholds.values, aspect='auto', cmap='RdBu_r', vmin=-0.3, vmax=0.3)
    ax_right.set_xticks(range(len(pivot_thresholds.columns)))
    ax_right.set_xticklabels([f'Ï„={tau:.1f}' for tau in pivot_thresholds.columns])
    ax_right.set_yticks(range(len(pivot_thresholds.index)))
    ax_right.set_yticklabels(pivot_thresholds.index, fontsize=8)
    ax_right.set_title('Threshold Distance Gap by Country (Female - Male)')
    ax_right.set_xlabel('Quantile')
    plt.colorbar(im2, ax=ax_right, label='Gap')
else:
    ax_right.text(0.5, 0.5, 'No threshold data available', ha='center', va='center')
    ax_right.set_title('Threshold Distance Gap by Country')

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/gender_gap_analysis.pdf', dpi=300, bbox_inches='tight')
plt.show()
_log(f"[3/4] å›¾è¡¨å·²ä¿å­˜åˆ° {OUTPUT_DIR}/gender_gap_analysis.pdf (åŒçƒ­å›¾)")

# æ‰“å°å…³é”®ç»“è®ºï¼ˆåˆ†å›½å®¶ç»´åº¦ï¼‰
print("=" * 60)
print("å…³é”®ç ”ç©¶ç»“è®ºï¼ˆåˆ†å›½å®¶ï¼‰")
print("=" * 60)

if len(country_gaps_df) > 0:
    # æŒ‰å›½å®¶ç»Ÿè®¡ç»“è®ºåˆ†å¸ƒ
    country_conclusions = []
    for country in country_gaps_df['country'].unique():
        country_data = country_gaps_df[country_gaps_df['country'] == country]
        bottom_avg = country_data[country_data['position'] == 'bottom']['gap_female_minus_male'].mean()
        top_avg = country_data[country_data['position'] == 'top']['gap_female_minus_male'].mean()
        conclusion = 'glass ceiling' if abs(top_avg) > abs(bottom_avg) else 'sticky floor'
        country_conclusions.append({'country': country, 'conclusion': conclusion, 
                                   'bottom_gap': bottom_avg, 'top_gap': top_avg})
    country_summary = pd.DataFrame(country_conclusions)
    
    
# ==================== Step 4: å¯¼å‡ºç»“æœ ====================
_log("[4/4] å†™å‡º CSV ä¸é…ç½®...")

# 1. æ€§åˆ«å·®åˆ†ä½è¡¨ï¼ˆä»…å›½å®¶çº§ï¼‰
if len(country_gaps_df) > 0:
    gap_combined = country_gaps_df.copy()
    gap_combined['analysis_level'] = 'country'
    gap_combined = gap_combined[['analysis_level', 'country', 'quantile', 'position', 
                                 'male_pred', 'female_pred', 'gap_female_minus_male',
                                 'female_ci_low_b1_q50', 'female_ci_high_b1_q50', 'female_sig_b1_q50', 'ci_level']]
else:
    gap_combined = pd.DataFrame(columns=['analysis_level','country','quantile','position','male_pred','female_pred','gap_female_minus_male'])

gap_combined.to_csv(f'{OUTPUT_DIR}/gender_gap_by_quantile.csv', index=False)
print(f"âœ“ æ€§åˆ«å·®åˆ†ä½è¡¨å·²ä¿å­˜: {OUTPUT_DIR}/gender_gap_by_quantile.csv")

# 2. é—¨æ§›è·ç¦»è¡¨ï¼ˆä»…å›½å®¶çº§ï¼‰
if len(country_thresholds_df) > 0:
    thresh_combined = country_thresholds_df.copy()
    thresh_combined['analysis_level'] = 'country'
    thresh_combined = thresh_combined[['analysis_level', 'country', 'quantile', 'position',
                                       'male_avg_distance', 'female_avg_distance', 'gap_female_minus_male']]
else:
    thresh_combined = pd.DataFrame(columns=['analysis_level','country','quantile','position','male_avg_distance','female_avg_distance','gap_female_minus_male'])

# 2.1 éšæœºä»£è¡¨äººå¹³å‡å·®ï¼ˆé™„åŠ è¡¨ï¼‰
if len(avg_refs_df) > 0:
    avg_refs_export = avg_refs_df.copy()
    avg_refs_export.to_csv(f'{OUTPUT_DIR}/avg_gap_random_refs.csv', index=False)
    print(f"âœ“ éšæœºä»£è¡¨äººå¹³å‡å·®è¡¨å·²ä¿å­˜: {OUTPUT_DIR}/avg_gap_random_refs.csv")

# 2.2 é¡¶éƒ¨å·®âˆ’åº•éƒ¨å·®ï¼ˆå«æ˜¾è‘—æ€§ï¼‰
if len(boot_summary_df) > 0:
    boot_summary_export = boot_summary_df.copy()
    boot_summary_export.to_csv(f'{OUTPUT_DIR}/top_minus_bottom_diff_with_ci.csv', index=False)
    print(f"âœ“ é¡¶éƒ¨å·®âˆ’åº•éƒ¨å·®ï¼ˆå«CIï¼‰å·²ä¿å­˜: {OUTPUT_DIR}/top_minus_bottom_diff_with_ci.csv")

thresh_combined.to_csv(f'{OUTPUT_DIR}/threshold_distance.csv', index=False)
print(f"âœ“ é—¨æ§›è·ç¦»è¡¨å·²ä¿å­˜: {OUTPUT_DIR}/threshold_distance.csv")

# 3. æ±‡æ€»ç»“è®ºè¡¨ï¼ˆä»…å›½å®¶çº§ï¼‰
summary_export = []
if len(country_gaps_df) > 0 and 'country_summary' in locals():
    for _, row in country_summary.iterrows():
        summary_export.append({
            'analysis_level': 'country',
            'country': row['country'],
            'bottom_gap_avg': row['bottom_gap'],
            'top_gap_avg': row['top_gap'],
            'gap_diff_bottom_minus_top': row['bottom_gap'] - row['top_gap'],
            'conclusion': row['conclusion'],
            'n_observations': int(country_gaps_df[country_gaps_df['country'] == row['country']].iloc[0]['n'])
        })

summary_df = pd.DataFrame(summary_export)
summary_df.to_csv(f'{OUTPUT_DIR}/analysis_summary.csv', index=False)
print(f"âœ“ æ±‡æ€»ç»“è®ºè¡¨å·²ä¿å­˜: {OUTPUT_DIR}/analysis_summary.csv")

# ä¿å­˜æ¨¡å‹é…ç½®ä¿¡æ¯
config_info = {
    'model_config': 'per-country models via fit_model()',
    'quantiles_analyzed': ALL_QUANTILES,
    'bottom_quantiles': BOTTOM_QUANTILES,
    'top_quantiles': TOP_QUANTILES,
    'countries_analyzed': int(country_gaps_df['country'].nunique()) if len(country_gaps_df) > 0 else 0,
    'analysis_timestamp': pd.Timestamp.now().isoformat()
}

import json
with open(f'{OUTPUT_DIR}/analysis_config.json', 'w') as f:
    json.dump(config_info, f, indent=2, default=str)
print(f"âœ“ åˆ†æé…ç½®å·²ä¿å­˜: {OUTPUT_DIR}/analysis_config.json")

print(f"\nğŸ‰ åˆ†æå®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° '{OUTPUT_DIR}/' ç›®å½•")
print("\næ ¸å¿ƒæ–‡ä»¶æ¸…å•:")
print(f"  ğŸ“Š gender_gap_by_quantile.csv - å›½å®¶çº§æ€§åˆ«å·®åˆ†ä½è¯¦è¡¨")
print(f"  ğŸ“ threshold_distance.csv - å›½å®¶çº§é—¨æ§›è·ç¦»åˆ†æè¯¦è¡¨") 
print(f"  ğŸ“‹ analysis_summary.csv - ç²˜åœ°æ¿/ç»ç’ƒå¤©èŠ±æ¿ç»“è®ºæ±‡æ€»")
print(f"  ğŸ“ˆ gender_gap_analysis.pdf - åŒçƒ­å›¾å¯è§†åŒ–")
print(f"  âš™ï¸  analysis_config.json - æ¨¡å‹é…ç½®ä¸å…ƒæ•°æ®")

# æœ€ç»ˆç ”ç©¶ç»“è®ºæ‘˜è¦
print("\n" + "=" * 80)
print("ğŸ” æœ€ç»ˆç ”ç©¶ç»“è®ºæ‘˜è¦")
print("=" * 80)
print(f"ç ”ç©¶é—®é¢˜: åˆ†æ Y10 èŒçº§ä¸­çš„æ€§åˆ«å·®å¼‚æ¨¡å¼ï¼ˆåˆ†å›½å®¶ï¼‰")
if len(country_gaps_df) > 0:
    print(f"å›½å®¶è¦†ç›–: {int(country_gaps_df['country'].nunique())} ä¸ªå›½å®¶")

print(f"\nå¯ç›´æ¥ç”¨äºæŠ¥å‘Šçš„å…³é”®æ•°æ®:")
print("å»ºè®®é˜…è¯» CSV çƒ­å›¾è€Œéå•ä¸€å…¨æ ·æœ¬æ›²çº¿ï¼›ç»“è®ºä»¥å›½å®¶çº§åˆ«ä¸ºå‡†ã€‚")
